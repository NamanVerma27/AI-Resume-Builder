# backend/.env.example
DATABASE_URL=./dev.db

# LLM adapter selection: 'mock' (default), 'openai', 'cohere', or 'gemini'
LLM_PROVIDER=mock

# OpenAI (server-side only)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# Cohere (server-side only)
COHERE_API_KEY=
COHERE_MODEL=command-xsmall-nightly

# Google Gemini (server-side only)
# Option A: API key (from Google Cloud / AI Studio). Use the key value here.
GEMINI_API_KEY=

# Option B: OAuth bearer token (ya29...); if using OAuth/service account, set this instead.
GEMINI_OAUTH_BEARER=

# Gemini model name (confirm the exact model id in docs / AI Studio)
GEMINI_MODEL=models/gemini-1.5-preview
GEMINI_ENDPOINT_BASE=https://generativelanguage.googleapis.com/v1beta2
